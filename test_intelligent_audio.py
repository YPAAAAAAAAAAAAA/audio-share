#!/usr/bin/env python3
"""
Step Realtime API æ™ºèƒ½éŸ³é¢‘åˆ†ç±»æµ‹è¯•
æµ‹è¯•ç¯å¢ƒéŸ³ vs äººå£°æ£€æµ‹ + 5-10ç§’å®æ—¶æ€»ç»“
"""

import asyncio
import websockets
import json
import base64
import numpy as np
import time

API_KEY = "8FyDGELcpTdfh1JNOoePkfXzCtExQHL8DSdEX9UYfl4dCsE77R4WIUOIJqanw0Cl"
WS_URL = "wss://api.stepfun.com/v1/realtime"

class IntelligentAudioTester:
    def __init__(self):
        self.websocket = None
        self.test_results = []
        self.current_test = None
        
    async def connect(self):
        """è¿æ¥åˆ°Step Realtime API"""
        try:
            self.websocket = await websockets.connect(
                f"{WS_URL}?model=step-audio-2-mini",
                additional_headers={
                    "Authorization": f"Bearer {API_KEY}"
                }
            )
            print("âœ… æˆåŠŸè¿æ¥åˆ°Step Realtime API")
            return True
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    async def send_session_config(self, test_scenario):
        """æ ¹æ®æµ‹è¯•åœºæ™¯å‘é€ä¸åŒçš„sessioné…ç½®"""
        
        if test_scenario == "environment_sound":
            instructions = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¯å¢ƒéŸ³åˆ†æåŠ©æ‰‹ã€‚
            å½“æ£€æµ‹åˆ°ç¯å¢ƒå£°éŸ³æ—¶ï¼Œè¯·ï¼š
            1. è¯†åˆ«å£°éŸ³ç±»å‹ï¼ˆè‡ªç„¶/æœºæ¢°/éŸ³ä¹ç­‰ï¼‰
            2. ç”¨3-6ä¸ªå­—æè¿°ç¯å¢ƒç‰¹å¾
            3. å¦‚æœå¬åˆ°äººå£°ï¼Œè¯·æ ‡æ³¨"æ£€æµ‹åˆ°äººå£°"
            ä¸“æ³¨äºç¯å¢ƒéŸ³åˆ†æï¼Œå“åº”è¦ç®€æ´ç²¾å‡†ã€‚"""
            
            voice = "qingchunshaonv"
            silence_duration = 300  # æ›´çŸ­çš„é™éŸ³æ£€æµ‹
            threshold = 0.3  # æ›´ä½çš„é˜ˆå€¼æ£€æµ‹ç¯å¢ƒéŸ³
            
        else:  # human_voice
            instructions = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­éŸ³æ€»ç»“åŠ©æ‰‹ã€‚
            å½“ç”¨æˆ·è¯´è¯æ—¶ï¼Œè¯·ï¼š
            1. å‡†ç¡®è½¬å½•ä¸­æ–‡è¯­éŸ³
            2. ç”¨5-8ä¸ªå­—æ€»ç»“æ ¸å¿ƒå†…å®¹
            3. è¯†åˆ«è¯­éŸ³æƒ…ç»ªå’Œç´§æ€¥ç¨‹åº¦
            4. å¦‚æœæ˜¯ç¯å¢ƒéŸ³ï¼Œè¯·æ ‡æ³¨"éäººå£°éŸ³é¢‘"
            ä¸“æ³¨äºäººå£°ç†è§£ï¼Œä¿æŒç®€æ´ç²¾å‡†ã€‚"""
            
            voice = "qingchunshaonv"
            silence_duration = 600  # æ ‡å‡†é™éŸ³æ£€æµ‹
            threshold = 0.5  # æ ‡å‡†é˜ˆå€¼
        
        config = {
            "event_id": f"session_config_{test_scenario}",
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": instructions,
                "voice": voice,
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "turn_detection": {
                    "type": "server_vad",
                    "threshold": threshold,
                    "silence_duration_ms": silence_duration
                }
            }
        }
        
        await self.websocket.send(json.dumps(config))
        print(f"ğŸ“¤ å‘é€{test_scenario}ä¸“ç”¨é…ç½®")
    
    async def generate_environment_audio(self, sound_type):
        """ç”Ÿæˆä¸åŒç±»å‹çš„ç¯å¢ƒéŸ³"""
        sample_rate = 16000
        duration = 3.0  # 3ç§’éŸ³é¢‘
        
        if sound_type == "nature":
            # ç”Ÿæˆé£å£°å’Œé¸Ÿå«å£°çš„ç»„åˆ
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            # é£å£° (ä½é¢‘å™ªéŸ³)
            wind = np.random.normal(0, 0.1, len(t)) * np.sin(2 * np.pi * 0.5 * t)
            # é¸Ÿå«å£° (é«˜é¢‘çŸ­è„‰å†²)
            bird_chirps = np.zeros(len(t))
            for i in range(5):  # 5å£°é¸Ÿå«
                start_idx = int(np.random.uniform(0.2, 2.5) * sample_rate)
                end_idx = start_idx + int(0.3 * sample_rate)
                if end_idx < len(t):
                    freq = np.random.uniform(800, 1200)
                    bird_chirps[start_idx:end_idx] = np.sin(2 * np.pi * freq * t[start_idx:end_idx]) * 0.3
            
            audio_data = (wind + bird_chirps) * 0.4
            
        elif sound_type == "mechanical":
            # ç”Ÿæˆæœºæ¢°è¿è½¬å£°
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            # ç”µæœºè½¬åŠ¨å£° (ç¨³å®šé¢‘ç‡)
            motor = np.sin(2 * np.pi * 60 * t) * 0.2  # 60Hz
            # é½¿è½®å£° (å‘¨æœŸæ€§å’”å“’å£°)
            gear_noise = np.random.normal(0, 0.1, len(t))
            audio_data = (motor + gear_noise) * 0.5
            
        elif sound_type == "music":
            # ç”Ÿæˆç®€å•çš„éŸ³ä¹æ—‹å¾‹
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            notes = [440, 494, 523, 587]  # A, B, C, D
            melody = np.zeros(len(t))
            note_duration = duration / len(notes)
            
            for i, freq in enumerate(notes):
                start_idx = int(i * note_duration * sample_rate)
                end_idx = int((i + 1) * note_duration * sample_rate)
                if end_idx <= len(t):
                    melody[start_idx:end_idx] = np.sin(2 * np.pi * freq * t[start_idx:end_idx])
            
            audio_data = melody * 0.3
            
        else:  # human_speech simulation
            # ç”Ÿæˆæ¨¡æ‹Ÿäººå£°çš„å¤æ‚æ³¢å½¢
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            # åŸºé¢‘ + è°æ³¢ç»“æ„æ¨¡æ‹Ÿäººå£°
            fundamental = 150  # åŸºé¢‘
            voice = (np.sin(2 * np.pi * fundamental * t) * 0.4 +
                    np.sin(2 * np.pi * fundamental * 2 * t) * 0.2 +
                    np.sin(2 * np.pi * fundamental * 3 * t) * 0.1)
            
            # æ·»åŠ è¯­éŸ³çš„åŒ…ç»œå˜åŒ–
            envelope = np.abs(np.sin(2 * np.pi * 3 * t))  # 3Hzçš„åŒ…ç»œå˜åŒ–
            audio_data = voice * envelope * 0.3
        
        # è½¬æ¢ä¸º16ä½PCM
        audio_int16 = np.clip(audio_data * 32767, -32767, 32767).astype(np.int16)
        audio_bytes = audio_int16.tobytes()
        
        return base64.b64encode(audio_bytes).decode()
    
    async def send_test_audio(self, audio_data, test_name):
        """å‘é€æµ‹è¯•éŸ³é¢‘å¹¶è®°å½•æ—¶é—´"""
        start_time = time.time()
        
        # åˆ†å—å‘é€éŸ³é¢‘ (æ¨¡æ‹Ÿå®æ—¶æµ)
        chunk_size = 3200  # 200msçš„éŸ³é¢‘æ•°æ®
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i+chunk_size]
            
            message = {
                "event_id": f"audio_chunk_{test_name}_{i//chunk_size}",
                "type": "input_audio_buffer.append",
                "audio": chunk
            }
            
            await self.websocket.send(json.dumps(message))
            await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå®æ—¶å‘é€
        
        print(f"ğŸ“¤ å‘é€{test_name}éŸ³é¢‘æ•°æ®")
        
        # æäº¤éŸ³é¢‘ç¼“å†²åŒº
        commit_message = {
            "event_id": f"commit_{test_name}",
            "type": "input_audio_buffer.commit"
        }
        await self.websocket.send(json.dumps(commit_message))
        
        return start_time
    
    async def run_classification_test(self, test_scenario, sound_type):
        """è¿è¡Œå•ä¸ªåˆ†ç±»æµ‹è¯•"""
        print(f"\nğŸ”¬ å¼€å§‹æµ‹è¯•: {test_scenario} - {sound_type}")
        
        self.current_test = {
            "scenario": test_scenario,
            "sound_type": sound_type,
            "start_time": time.time(),
            "responses": []
        }
        
        # é…ç½®session
        await self.send_session_config(test_scenario)
        await asyncio.sleep(1)
        
        # ç”Ÿæˆå’Œå‘é€æµ‹è¯•éŸ³é¢‘
        if sound_type in ["nature", "mechanical", "music"]:
            audio_data = await self.generate_environment_audio(sound_type)
        else:  # human_speech
            audio_data = await self.generate_environment_audio("human_speech")
        
        send_start = await self.send_test_audio(audio_data, f"{test_scenario}_{sound_type}")
        
        # ç­‰å¾…å“åº” (æœ€å¤š10ç§’)
        response_timeout = 10
        await asyncio.sleep(response_timeout)
        
        # åˆ†æç»“æœ
        await self.analyze_test_result()
        
    async def analyze_test_result(self):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not self.current_test:
            return
        
        test = self.current_test
        total_time = time.time() - test["start_time"]
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœåˆ†æ:")
        print(f"   åœºæ™¯: {test['scenario']}")
        print(f"   éŸ³é¢‘ç±»å‹: {test['sound_type']}")
        print(f"   æ€»ç”¨æ—¶: {total_time:.2f}ç§’")
        print(f"   å“åº”æ•°é‡: {len(test['responses'])}")
        
        # æ£€æŸ¥å“åº”è´¨é‡
        has_transcription = any("transcript" in r for r in test["responses"])
        has_summary = any("content" in r and len(r.get("content", "")) >= 3 for r in test["responses"])
        response_time = min([r.get("time", 999) for r in test["responses"]] + [999])
        
        print(f"   âœ… è½¬å½•æ£€æµ‹: {'æ˜¯' if has_transcription else 'å¦'}")
        print(f"   âœ… æ™ºèƒ½æ€»ç»“: {'æ˜¯' if has_summary else 'å¦'}")
        print(f"   â±ï¸ é¦–æ¬¡å“åº”: {response_time:.2f}ç§’")
        
        # è¯„ä¼°å‡†ç¡®æ€§
        accuracy_score = self.evaluate_accuracy(test)
        print(f"   ğŸ¯ å‡†ç¡®åº¦è¯„åˆ†: {accuracy_score}/5")
        
        self.test_results.append(test)
        self.current_test = None
    
    def evaluate_accuracy(self, test):
        """è¯„ä¼°åˆ†ç±»å‡†ç¡®æ€§"""
        scenario = test["scenario"]
        sound_type = test["sound_type"]
        responses = test["responses"]
        
        score = 0
        
        # åŸºç¡€åˆ† - æœ‰å“åº”
        if responses:
            score += 1
        
        # æ—¶æ•ˆåˆ† - 10ç§’å†…å“åº”
        fast_response = any(r.get("time", 999) <= 10 for r in responses)
        if fast_response:
            score += 1
        
        # å†…å®¹åˆ† - å“åº”ç›¸å…³æ€§
        relevant_content = False
        for r in responses:
            content = r.get("content", "").lower()
            if scenario == "environment_sound":
                if sound_type == "nature" and ("è‡ªç„¶" in content or "é£" in content or "é¸Ÿ" in content):
                    relevant_content = True
                elif sound_type == "mechanical" and ("æœºæ¢°" in content or "ç”µæœº" in content or "è¿è½¬" in content):
                    relevant_content = True
                elif sound_type == "music" and ("éŸ³ä¹" in content or "æ—‹å¾‹" in content or "ä¹éŸ³" in content):
                    relevant_content = True
            elif scenario == "human_voice":
                if sound_type == "human_speech" and ("è¯­éŸ³" in content or "è¯´è¯" in content or "äººå£°" in content):
                    relevant_content = True
        
        if relevant_content:
            score += 2
        
        # é•¿åº¦åˆ† - 3-8å­—æ€»ç»“
        appropriate_length = any(3 <= len(r.get("content", "")) <= 10 for r in responses)
        if appropriate_length:
            score += 1
        
        return score
    
    async def listen_for_responses(self):
        """ç›‘å¬æœåŠ¡å™¨å“åº”å¹¶è®°å½•æµ‹è¯•æ•°æ®"""
        async for message in self.websocket:
            try:
                data = json.loads(message)
                event_type = data.get("type", "unknown")
                
                # è®°å½•å“åº”æ—¶é—´
                if self.current_test:
                    response_data = {
                        "type": event_type,
                        "time": time.time() - self.current_test["start_time"],
                        "data": data
                    }
                
                if event_type == "session.created":
                    print("âœ… Sessionåˆ›å»ºæˆåŠŸ")
                    
                elif event_type == "session.updated":
                    print("âœ… Sessioné…ç½®æ›´æ–°æˆåŠŸ")
                    
                elif event_type == "conversation.item.input_audio_transcription.completed":
                    transcript = data.get("transcript", "")
                    print(f"ğŸ¤ è½¬å½•å®Œæˆ: {transcript}")
                    
                    if self.current_test:
                        response_data["transcript"] = transcript
                        self.current_test["responses"].append(response_data)
                    
                elif event_type == "response.text.done":
                    content = data.get("content", "")
                    print(f"ğŸ’¡ AIåˆ†æç»“æœ: {content}")
                    
                    if self.current_test:
                        response_data["content"] = content
                        self.current_test["responses"].append(response_data)
                    
                elif event_type == "response.audio_transcript.done":
                    transcript = data.get("transcript", "")
                    print(f"ğŸ¤– AIå›å¤è½¬å½•: {transcript}")
                    
                    if self.current_test:
                        response_data["ai_transcript"] = transcript
                        self.current_test["responses"].append(response_data)
                    
                elif event_type == "error":
                    error_info = data.get("error", {})
                    print(f"âŒ é”™è¯¯: {error_info.get('message', 'Unknown error')}")
                    
                    if self.current_test:
                        response_data["error"] = error_info
                        self.current_test["responses"].append(response_data)
                    
            except Exception as e:
                print(f"âŒ è§£ææ¶ˆæ¯å¤±è´¥: {e}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•° - å…¨é¢æµ‹è¯•æ™ºèƒ½éŸ³é¢‘åˆ†ç±»"""
    tester = IntelligentAudioTester()
    
    print("ğŸ§ª å¼€å§‹æ™ºèƒ½éŸ³é¢‘åˆ†ç±»å…¨é¢æµ‹è¯•")
    print(f"ğŸ“¡ APIå¯†é’¥: {API_KEY[:20]}...")
    print("=" * 60)
    
    # è¿æ¥æµ‹è¯•
    if not await tester.connect():
        print("âŒ è¿æ¥å¤±è´¥ï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    # å¯åŠ¨å“åº”ç›‘å¬
    listen_task = asyncio.create_task(tester.listen_for_responses())
    
    try:
        # æµ‹è¯•åœºæ™¯å®šä¹‰
        test_scenarios = [
            ("environment_sound", "nature"),      # ç¯å¢ƒéŸ³æ£€æµ‹ - è‡ªç„¶éŸ³
            ("environment_sound", "mechanical"),  # ç¯å¢ƒéŸ³æ£€æµ‹ - æœºæ¢°éŸ³
            ("environment_sound", "music"),       # ç¯å¢ƒéŸ³æ£€æµ‹ - éŸ³ä¹
            ("human_voice", "human_speech"),      # äººå£°æ£€æµ‹ - äººå£°
            ("human_voice", "nature"),            # äººå£°æ£€æµ‹ - è‡ªç„¶éŸ³(è¯¯åˆ¤æµ‹è¯•)
            ("environment_sound", "human_speech") # ç¯å¢ƒéŸ³æ£€æµ‹ - äººå£°(è¯¯åˆ¤æµ‹è¯•)
        ]
        
        print("ğŸ¯ æµ‹è¯•è®¡åˆ’:")
        for i, (scenario, sound_type) in enumerate(test_scenarios, 1):
            print(f"   {i}. {scenario} â†’ {sound_type}")
        print()
        
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        for i, (scenario, sound_type) in enumerate(test_scenarios, 1):
            print(f"\n{'='*20} æµ‹è¯• {i}/{len(test_scenarios)} {'='*20}")
            await tester.run_classification_test(scenario, sound_type)
            
            if i < len(test_scenarios):
                print("â¸ï¸ ç­‰å¾…3ç§’åè¿›è¡Œä¸‹ä¸€æµ‹è¯•...")
                await asyncio.sleep(3)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        print(f"\n{'='*60}")
        print("ğŸ“‹ æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print(f"{'='*60}")
        
        total_tests = len(tester.test_results)
        total_score = sum(tester.evaluate_accuracy(test) for test in tester.test_results)
        max_score = total_tests * 5
        
        print(f"æ€»æµ‹è¯•æ•°é‡: {total_tests}")
        print(f"æ€»å¾—åˆ†: {total_score}/{max_score} ({total_score/max_score*100:.1f}%)")
        print()
        
        # è¯¦ç»†ç»“æœ
        for i, test in enumerate(tester.test_results, 1):
            score = tester.evaluate_accuracy(test)
            status = "âœ… ä¼˜ç§€" if score >= 4 else "âš ï¸ è‰¯å¥½" if score >= 3 else "âŒ éœ€ä¼˜åŒ–"
            
            print(f"{i}. {test['scenario']} â†’ {test['sound_type']}: {score}/5 {status}")
            
            # æ˜¾ç¤ºå“åº”å†…å®¹
            for response in test["responses"]:
                if "content" in response:
                    print(f"   ğŸ’¬ AIå›å¤: {response['content']}")
                if "transcript" in response:
                    print(f"   ğŸ“ è½¬å½•: {response['transcript']}")
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼æ™ºèƒ½éŸ³é¢‘åˆ†ç±»ç³»ç»Ÿè¯„ä¼°å¾—åˆ†: {total_score/max_score*100:.1f}%")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        listen_task.cancel()
        if tester.websocket:
            await tester.websocket.close()
        print("ğŸ”Œ è¿æ¥å·²å…³é—­")

if __name__ == "__main__":
    # ä¾èµ–æ£€æŸ¥
    try:
        import websockets
        import numpy as np
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·è¿è¡Œ: pip install websockets numpy")
        exit(1)
    
    # è¿è¡Œå…¨é¢æµ‹è¯•
    asyncio.run(main())